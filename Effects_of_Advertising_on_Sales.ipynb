{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PSamita/MIT-Course/blob/main/Effects_of_Advertising_on_Sales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM7KaMsIyx5q"
      },
      "source": [
        "# Effects of Advertising on Sales\n",
        "\n",
        "### LVC 1 - Introduction to Supervised Learning: Regression\n",
        "\n",
        "\n",
        "## Context and Problem\n",
        "\n",
        "- An interesting application of regression is to quantify the effect of advertisement on sales. Various channels of advertisement are newspaper, TV, radio, etc. \n",
        "- In this case study, we will have a look at the advertising data of a company and try to see its effect on sales.\n",
        "- We will also try to predict the sales given the different parameters of advertising. \n",
        "\n",
        "\n",
        "## Data Information\n",
        "\n",
        "The data at hand has three features about the spending on advertising and the target variable is the net sales. Attributes are:\n",
        "\n",
        "- TV    - Independent variable quantifying budget for TV ads\n",
        "- Radio - Independent variable quantifying budget for radio ads \n",
        "- News  - Independent variable quantifying budget for news ads\n",
        "- Sales - Dependent variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzjQEUms29nL"
      },
      "source": [
        "### Let us start by importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbek6djw26sQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eujy4X4H5Vgp"
      },
      "outputs": [],
      "source": [
        "# Let us import the files from our system. Note that you can also load the data from the drive. \n",
        "# The below code is applicable only if you are working on Google Colab, In case you are using Jupyter Notebook, you can directly use pd.read_csv(filename) to load data into dataframe\n",
        "\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIbGMZS36De1"
      },
      "outputs": [],
      "source": [
        "Ad_df = pd.read_csv('Advertising.csv')\n",
        "\n",
        "# we have loaded the data into the Ad_df data frame. Let us now have a quick look.\n",
        "Ad_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQD08slX6tVt"
      },
      "outputs": [],
      "source": [
        "# we can drop the first column as it is just the index\n",
        "Ad_df.drop(columns = 'Unnamed: 0', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHN8-pYv7IAP"
      },
      "outputs": [],
      "source": [
        "Ad_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPtSvD8T-ALA"
      },
      "outputs": [],
      "source": [
        "Ad_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtclE25ghs4f"
      },
      "source": [
        "**Observations:** All the variables are of float data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdPHnnpw_9oV"
      },
      "source": [
        "### Let us now start with the simple linear regression. We will use one feature at a time and have a look at the target variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4UTFBGd9_Dr"
      },
      "outputs": [],
      "source": [
        "# Dataset is stored in a Pandas Dataframe. Let us take out all the variables in a numpy array.\n",
        "Sales = Ad_df.Sales.values.reshape(len(Ad_df['Sales']), 1)\n",
        "TV = Ad_df.TV.values.reshape(len(Ad_df['Sales']), 1)\n",
        "Radio = Ad_df.Radio.values.reshape(len(Ad_df['Sales']), 1)\n",
        "Newspaper = Ad_df.Newspaper.values.reshape(len(Ad_df['Sales']), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4CKboT-CBgP"
      },
      "outputs": [],
      "source": [
        "# let us fit the simple linear regression model with the TV feature\n",
        "tv_model = linear_model.LinearRegression()\n",
        "tv_model.fit(TV, Sales)\n",
        "coeffs_tv = np.array(list(tv_model.intercept_.flatten()) + list(tv_model.coef_.flatten()))\n",
        "coeffs_tv = list(coeffs_tv)\n",
        "\n",
        "# let us fit the simple linear regression model with the Radio feature\n",
        "radio_model = linear_model.LinearRegression()\n",
        "radio_model.fit(Radio, Sales)\n",
        "coeffs_radio = np.array(list(radio_model.intercept_.flatten()) + list(radio_model.coef_.flatten()))\n",
        "coeffs_radio = list(coeffs_radio)\n",
        "\n",
        "# let us fit the simple linear regression model with the Newspaper feature\n",
        "newspaper_model = linear_model.LinearRegression()\n",
        "newspaper_model.fit(Newspaper, Sales)\n",
        "coeffs_newspaper = np.array(list(newspaper_model.intercept_.flatten()) + list(newspaper_model.coef_.flatten()))\n",
        "coeffs_newspaper = list(coeffs_newspaper)\n",
        "\n",
        "# let us store the above results in a dictionary and then display using a dataframe\n",
        "dict_Sales = {}\n",
        "dict_Sales[\"TV\"] = coeffs_tv\n",
        "dict_Sales[\"Radio\"] = coeffs_radio\n",
        "dict_Sales[\"Newspaper\"] = coeffs_newspaper\n",
        "\n",
        "metric_Df_SLR =  pd.DataFrame(dict_Sales)\n",
        "metric_Df_SLR.index = ['Intercept', 'Coefficient']\n",
        "metric_Df_SLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFjl_ZoW_njD"
      },
      "outputs": [],
      "source": [
        "# Let us now calculate R^2\n",
        "tv_rsq = tv_model.score(TV, Sales)\n",
        "radio_rsq = radio_model.score(Radio, Sales)\n",
        "newspaper_rsq = newspaper_model.score(Newspaper, Sales)\n",
        "\n",
        "print(\"TV simple linear regression R-Square :\", tv_rsq)\n",
        "print(\"Radio simple linear regression R-Square :\", radio_rsq)\n",
        "print(\"Newspaper simple linear regression R-Square :\", newspaper_rsq)\n",
        "list_rsq = [tv_rsq, radio_rsq, newspaper_rsq]\n",
        "list_rsq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMAZXp21AGsB"
      },
      "outputs": [],
      "source": [
        "metric_Df_SLR.loc['R-Squared'] = list_rsq\n",
        "metric_Df_SLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es84uRdJhs4i"
      },
      "source": [
        "**Observations:** We can see that TV has the highest R^2 value i.e. 61% followed by Radio and Newspaper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x63PBJxhs4i"
      },
      "source": [
        "Let's try to visualize the best fit line using the regression plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R45kkSNQxPx"
      },
      "outputs": [],
      "source": [
        "plt.scatter(TV, Sales,  color='red')\n",
        "plt.xlabel('TV Ads')\n",
        "plt.ylabel('Sales')\n",
        "plt.plot(TV, tv_model.predict(TV), color='blue', linewidth=3)\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(Radio, Sales,  color='red')\n",
        "plt.xlabel('Radio Ads')\n",
        "plt.ylabel('Sales')\n",
        "plt.plot(Radio, radio_model.predict(Radio), color='blue', linewidth=3)\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(Newspaper, Sales,  color='red')\n",
        "plt.xlabel('Newspaper Ads')\n",
        "plt.ylabel('Sales')\n",
        "plt.plot(Newspaper, newspaper_model.predict(Newspaper), color='blue', linewidth=3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxiuPBWPQnKm"
      },
      "source": [
        "## Multiple Linear Regression\n",
        "\n",
        "- Let us now build a multiple linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0XdOsasQ_uq"
      },
      "outputs": [],
      "source": [
        "mlr_model = linear_model.LinearRegression()\n",
        "mlr_model.fit(Ad_df[['TV', 'Radio', 'Newspaper']], Ad_df['Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f45Fynt_WSIr"
      },
      "outputs": [],
      "source": [
        "Ad_df['Sales_Predicted']  = mlr_model.predict(Ad_df[['TV', 'Radio', 'Newspaper']]) \n",
        "Ad_df['Error'] = (Ad_df['Sales_Predicted'] - Ad_df['Sales'])**2\n",
        "MSE_MLR = Ad_df['Error'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IR7lKmrYCpl"
      },
      "outputs": [],
      "source": [
        "MSE_MLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXJ6F7b5OqPI"
      },
      "outputs": [],
      "source": [
        "mlr_model.score(Ad_df[['TV', 'Radio', 'Newspaper']], Ad_df['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsZJ-jimhs4k"
      },
      "source": [
        "**Observations:** The R^2 value for the multiple linear regression comes out to be 89.7% i.e. way better than simple linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UijVypbEhs4k"
      },
      "source": [
        "Let's now try to use statsmodel to get a more detailed model interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjFCh7tkWf0M"
      },
      "outputs": [],
      "source": [
        "# let us get a more detailed model through statsmodel.\n",
        "import statsmodels.formula.api as smf\n",
        "lm1 = smf.ols(formula= 'Sales ~ TV+Radio+Newspaper', data = Ad_df).fit()\n",
        "lm1.params\n",
        "print(lm1.summary())  #Inferential statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2aGVrtKnY7G"
      },
      "outputs": [],
      "source": [
        "print(\"*************Parameters**************\")\n",
        "print(lm1.params)\n",
        "print(\"*************P-Values**************\")\n",
        "print(lm1.pvalues)\n",
        "print(\"************Standard Errors***************\")\n",
        "print(lm1.bse) \n",
        "print(\"*************Confidence Interval**************\")\n",
        "print(lm1.conf_int())\n",
        "print(\"*************Error Covariance Matrix**************\")\n",
        "print(lm1.cov_params())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drlo5QI2h2oY"
      },
      "source": [
        "### Visualizing the confidence bands in Simple linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daxXRhFiip3e"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.lmplot(x = 'TV', y = 'Sales', data = Ad_df)\n",
        "\n",
        "sns.lmplot(x = 'Radio', y = 'Sales', data = Ad_df )\n",
        "\n",
        "sns.lmplot(x = 'Newspaper', y = 'Sales', data = Ad_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGCcusUsz_Az"
      },
      "source": [
        "# LVC  2 - Model Evaluation: Cross validation and Bootstrapping\n",
        "\n",
        "- We realize that the newspaper can be omitted from the list of significant features owing to the p-value.\n",
        "- Let us now run the regression analysis adding a multiplicative feature in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTSASn2az9-B"
      },
      "outputs": [],
      "source": [
        "Ad_df['TVandRadio'] = Ad_df['TV']*Ad_df['Radio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_EfN22CWf5W"
      },
      "outputs": [],
      "source": [
        "# let us remove the sales_predicted and the error column generated earlier\n",
        "Ad_df.drop(columns = [\"Error\", \"Sales_Predicted\"], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz8DKNiF2QxK"
      },
      "outputs": [],
      "source": [
        "# Let us do the modelling with the new feature.\n",
        "import statsmodels.formula.api as smf\n",
        "lm2 = smf.ols(formula= 'Sales ~ TV+Radio+Newspaper+TVandRadio', data = Ad_df).fit()\n",
        "lm2.params\n",
        "print(lm2.summary())  #Inferential statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NslaNwMQFjL1"
      },
      "source": [
        "**Observations**\n",
        "- We see an increase in the R-square here. However, is this model useful for prediction? Does it predict well for the unseen data? Let us find out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d46mQv0BUKZ8"
      },
      "source": [
        "## Performance assessment, testing and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EAcqssG3pr0"
      },
      "source": [
        "### Train, Test, and Validation set\n",
        "- We will split data into three sets, one to train the model, one to validate the model performance (not seen during training) and make improvements, and the last to test the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQTTvaQ_3C6D"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRerX1zyDUlM"
      },
      "outputs": [],
      "source": [
        "features_base = [i for i in Ad_df.columns if i not in (\"Sales\" , \"TVandRadio\")]\n",
        "features_added = [i for i in Ad_df.columns if i not in \"Sales\"]\n",
        "target  = 'Sales'\n",
        "train, test = train_test_split(Ad_df, test_size = 0.10, train_size = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztuTrjlsDUq0"
      },
      "outputs": [],
      "source": [
        "train, validation = train_test_split(train, test_size = 0.2, train_size = 0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgm44JjJDUtK"
      },
      "outputs": [],
      "source": [
        "train.shape, validation.shape,test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCsbEBPoDUwm"
      },
      "outputs": [],
      "source": [
        "# now let us start with the modelling\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "mlr = LinearRegression()\n",
        "mlr.fit(train[features_base], train[target])\n",
        "print(\"*********Training set Metrics**************\")\n",
        "print(\"R-Squared:\", mlr.score(train[features_base], train[target]))\n",
        "se_train = (train[target] - mlr.predict(train[features_base]))**2\n",
        "mse_train = se_train.mean()\n",
        "print('MSE: ', mse_train)\n",
        "print(\"********Validation set Metrics**************\")\n",
        "print(\"R-Squared:\", mlr.score(validation[features_base], validation[target]))\n",
        "se_val = (validation[target] - mlr.predict(validation[features_base]))**2\n",
        "mse_val = se_val.mean()\n",
        "print('MSE: ', mse_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhMVT0OoI-ZR"
      },
      "outputs": [],
      "source": [
        "# Can we increase the model performance by adding the new feature? \n",
        "# We found that to be the case in the analysis above but let's check the same for the validation dataset\n",
        "\n",
        "mlr_added_feature = LinearRegression()\n",
        "mlr_added_feature.fit(train[features_added], train[target])\n",
        "print(\"*********Training set Metrics**************\")\n",
        "print(\"R-Squared:\", mlr_added_feature.score(train[features_added], train[target]))\n",
        "se_train = (train[target] - mlr_added_feature.predict(train[features_added]))**2\n",
        "mse_train = se_train.mean()\n",
        "print('MSE: ', mse_train)\n",
        "print(\"********Validation set Metrics**************\")\n",
        "print(\"R-Squared:\", mlr_added_feature.score(validation[features_added], validation[target]))\n",
        "se_val = (validation[target] - mlr_added_feature.predict(validation[features_added]))**2\n",
        "mse_val = se_val.mean()\n",
        "print('MSE: ', mse_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6lpvtsONOad"
      },
      "source": [
        "**Observations**\n",
        "- We found the R-squared increased as we would expect after adding a feature. Also the error decreased. Let us now fit a regularized model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRLnVLsn6pQG"
      },
      "source": [
        "## Regularization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvJSmJcAQ5-L"
      },
      "outputs": [],
      "source": [
        "features_added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZoBlRnCKge6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#fitting Ridge with the default features\n",
        "ridge = Ridge()\n",
        "ridge.fit(train[features_added], train[target])\n",
        "\n",
        "print(\"*********Training set Metrics**************\")\n",
        "print(\"R-Squared:\", ridge.score(train[features_added], train[target]))\n",
        "se_train = (train[target] - ridge.predict(train[features_added]))**2\n",
        "mse_train = se_train.mean()\n",
        "print('MSE: ', mse_train)\n",
        "print(\"********Validation set Metrics**************\")\n",
        "print(\"R-Squared:\", ridge.score(validation[features_added], validation[target]))\n",
        "se_val = (validation[target] - ridge.predict(validation[features_added]))**2\n",
        "mse_val = se_val.mean()\n",
        "print('MSE: ', mse_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL3Px7TORUVN"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#fitting Lasso with the default features\n",
        "lasso = Lasso()\n",
        "lasso.fit(train[features_added], train[target])\n",
        "\n",
        "print(\"*********Training set Metrics**************\")\n",
        "print(\"R-Squared:\", lasso.score(train[features_added], train[target]))\n",
        "se_train = (train[target] - lasso.predict(train[features_added]))**2\n",
        "mse_train = se_train.mean()\n",
        "print('MSE: ', mse_train)\n",
        "print(\"********Validation set Metrics**************\")\n",
        "print(\"R-Squared:\", lasso.score(validation[features_added], validation[target]))\n",
        "se_val = (validation[target] - lasso.predict(validation[features_added]))**2\n",
        "mse_val = se_val.mean()\n",
        "print('MSE: ', mse_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auLl5-cWRhKb"
      },
      "outputs": [],
      "source": [
        "#Let us predict on the unseen data using Ridge\n",
        "\n",
        "rsq_test = ridge.score(test[features_added], test[target])\n",
        "se_test = (test[target] - ridge.predict(test[features_added]))**2\n",
        "mse_test = se_test.mean()\n",
        "\n",
        "print(\"*****************Test set Metrics******************\")\n",
        "\n",
        "print(\"Rsquared: \", rsq_test)\n",
        "print(\"MSE: \", mse_test)\n",
        "print(\"Intercept is {} and Coefficients are {}\".format(ridge.intercept_, ridge.coef_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvdZcoUc9r4C"
      },
      "source": [
        "- We will now evaluate the performance using the LooCV and KFold methods.\n",
        "\n",
        "### K-Fold and LooCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY9Rz4rf9ql5"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMcwry-h64ZA"
      },
      "outputs": [],
      "source": [
        "ridgeCV = Ridge()\n",
        "cvs = cross_val_score(ridgeCV, Ad_df[features_added], Ad_df[target], cv = 10)\n",
        "print(\"Mean Score:\")\n",
        "print(cvs.mean(), \"\\n\")\n",
        "print(\"Confidence Interval:\")\n",
        "cvs.mean() - cvs.std(), cvs.mean() + cvs.std() \n",
        "\n",
        "# note that the same can be set as LooCV if cv parameter above is set to n, i.e, 200."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id70R6LjYLEW"
      },
      "source": [
        "## Extra: Statsmodel to fit regularized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVfz6N4yCT09"
      },
      "outputs": [],
      "source": [
        "# You can also use the statsmodel for the regularization using the below code\n",
        "# import statsmodels.formula.api as smf\n",
        "# We will use the below code to fit a regularized regression.\n",
        "\n",
        "\n",
        "# Here, lasso is fit\n",
        "# lm3 = smf.ols(formula= 'Sales ~ TV+Radio+Newspaper+TVandRadio', data = Ad_df).fit_regularized(method = 'elastic_net', L1_wt = 1)\n",
        "# print(\"*************Parameters**************\")\n",
        "# print(lm3.params)\n",
        "\n",
        "# Here, ridge regularization has been fit\n",
        "# lm4 = smf.ols(formula= 'Sales ~ TV+Radio+Newspaper+TVandRadio', data = Ad_df).fit_regularized(method = 'elastic_net', L1_wt = 0)\n",
        "# print(\"*************Parameters**************\")\n",
        "# print(lm4.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6veKXLlmMWr"
      },
      "source": [
        "## Bootstrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FcvUb-YmLUP"
      },
      "outputs": [],
      "source": [
        "# let us get a more detailed model through statsmodel.\n",
        "import statsmodels.formula.api as smf\n",
        "lm2 = smf.ols(formula= 'Sales ~ TV', data = Ad_df).fit()\n",
        "lm2.params\n",
        "print(lm2.summary())  #Inferential statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qjK1Fn9UOJT"
      },
      "outputs": [],
      "source": [
        "#Now, let us calculate the slopes a 1000 times using bootstrapping\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "\n",
        "Slope = []\n",
        "for i in range(1000):\n",
        "  bootstrap_df = Ad_df.sample(n = 200, replace = True )\n",
        "  lm3 = smf.ols(formula= 'Sales ~ TV', data = bootstrap_df).fit()\n",
        "  Slope.append(lm3.params.TV)\n",
        "  \n",
        "  plt.xlabel('TV Ads')\n",
        "  plt.ylabel('Sales')\n",
        "  plt.plot(bootstrap_df['TV'], lm3.predict(bootstrap_df['TV']), color='green', linewidth=3)\n",
        "  \n",
        "plt.scatter(Ad_df['TV'], Ad_df['Sales'],  color=(0,0,0.5))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my0E81YkGwCN"
      },
      "outputs": [],
      "source": [
        "# Let's now find out the 2.5 and 97.5 percentile for the slopes obtained\n",
        "import numpy as np\n",
        "\n",
        "Slope = np.array(Slope)\n",
        "Sort_Slope = np.sort(Slope)\n",
        "\n",
        "\n",
        "Slope_limits = np.percentile(Sort_Slope, (2.5, 97.5))\n",
        "Slope_limits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfuLE-9Hoh2G"
      },
      "outputs": [],
      "source": [
        "# Plotting the slopes and the upper and the lower limits\n",
        "\n",
        "plt.hist(Slope, 50)\n",
        "plt.axvline(Slope_limits[0], color = 'r')\n",
        "plt.axvline(Slope_limits[1], color = 'r')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}